#!/usr/bin/env python3
"""
download_enclosures.py

Robust downloader for podcast episodes from the CSV generated by
tools/curation/summarize_audio_results.py (episodes_ready_for_download.csv).

Improvements:
- Multiple strategies per item:
    1) Try enclosure_url (direct audio)
    2) If that fails, try episode page URL
    3) If that fails, try notes_url (often contains the player that yields a fresh signed URL)
- Adds desktop User-Agent and optional Referer header to reduce 403s
- Longer socket timeout, more retries, per-attempt backoff
- Strips enclosure query params as a last resort (some signed URLs break if stale)
- Host-level failure summary

Usage:
  python3 tools/media/download_enclosures.py \
    --src reports/audio_scan/episodes_ready_for_download.csv \
    --out downloads/audio \
    --fformat mp3 \
    --rate_limit 1M

Tips:
- If a host systematically fails (e.g., KPFA archives timeouts), re-run with --only-hosts or --skip-hosts to isolate.
"""

import argparse, csv, os, subprocess, time
from pathlib import Path
from urllib.parse import urlparse, urlsplit, urlunsplit

SAFE = str.maketrans({"/":"_", "\\":"_", ":":"-", "|":"-", "?":"", "*":"", "\"":"'", "<":"(", ">":")"})

AUDIO_EXTS = (".mp3",".m4a",".aac",".ogg",".oga",".opus",".mp4")

def safe(s: str|None) -> str:
    s = (s or "").strip()
    return (s[:200] if s else "untitled").translate(SAFE)

def guess_ext(url: str) -> str:
    try:
        path = urlparse(url).path.lower()
        for ext in AUDIO_EXTS:
            if path.endswith(ext): return ext
    except Exception:
        pass
    return ".mp3"

def host_of(u: str | None) -> str | None:
    if not u: return None
    try:
        h = urlparse(u).netloc.lower()
        return h.split(":")[0]
    except Exception:
        return None

def strip_query(u: str) -> str:
    parts = list(urlsplit(u))
    parts[3] = ""  # query
    parts[4] = ""  # fragment
    return urlunsplit(parts)

def build_cmd(out_path: Path, url: str, referer: str | None, fformat: str, rate_limit: str | None) -> list[str]:
    cmd = [
        "yt-dlp", url,
        "-o", str(out_path),
        "--no-playlist",
        "--no-progress",
        "--quiet", "--no-warnings",
        "--retries", "5",
        "--retry-sleep", "2",
        "--fragment-retries", "5",
        "--socket-timeout", "60",
        "--concurrent-fragments", "5",
        "--http-chunk-size", "10M",
        "--extract-audio", "--audio-format", fformat,
        "--user-agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
    ]
    if referer:
        cmd += ["--add-header", f"Referer: {referer}"]
    if rate_limit:
        cmd += ["--rate-limit", rate_limit]
    return cmd

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--src", required=True, help="episodes_ready_for_download.csv")
    ap.add_argument("--out", default="downloads/audio", help="Output folder")
    ap.add_argument("--fformat", default="mp3", choices=["mp3","m4a","aac","opus","ogg"], help="Target audio format")
    ap.add_argument("--rate_limit", default=None, help="yt-dlp --rate-limit, e.g. 1M")
    ap.add_argument("--only-hosts", default=None, help="Comma-separated list of hosts to include")
    ap.add_argument("--skip-hosts", default=None, help="Comma-separated list of hosts to skip")
    ap.add_argument("--dry-run", action="store_true", help="List planned downloads without running yt-dlp")
    args = ap.parse_args()

    only_hosts = set(h.strip().lower() for h in args.only_hosts.split(",")) if args.only_hosts else None
    skip_hosts = set(h.strip().lower() for h in args.skip_hosts.split(",")) if args.skip_hosts else set()

    outdir = Path(args.out); outdir.mkdir(parents=True, exist_ok=True)
    ok_log   = outdir.parent / "downloads_ok.csv"
    fail_log = outdir.parent / "downloads_fail.csv"

    with open(args.src, "r", encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    oks, fails = [], []
    host_fail_counts = {}

    for i, r in enumerate(rows, 1):
        enc = (r.get("enclosure_url") or "").strip()
        page = (r.get("url") or "").strip()
        notes = (r.get("notes_url") or "").strip()

        # Host filters
        h_enc, h_page, h_notes = host_of(enc), host_of(page), host_of(notes)
        picked_host = h_enc or h_page or h_notes
        if only_hosts and picked_host and picked_host not in only_hosts: 
            continue
        if picked_host in skip_hosts:
            continue

        podcast = safe(r.get("podcast_name") or "(unknown podcast)")
        title   = safe(r.get("title"))
        date    = (r.get("published") or "").split("T")[0] if r.get("published") else ""
        # Default filename based on enclosure (or page) extension
        ext_src = guess_ext(enc or page or notes)
        rel = Path(podcast) / (f"{date}__{title}{ext_src}" if date else f"{title}{ext_src}")
        dest = outdir / rel
        dest.parent.mkdir(parents=True, exist_ok=True)

        if dest.exists() and dest.stat().st_size > 0:
            oks.append({**r, "path": str(dest), "status": "already"})
            continue

        if args.dry_run:
            print(f"[DRY] Would download: {enc or page or notes} -> {dest}")
            continue

        # Strategy 1: direct enclosure
        tried = []
        if enc:
            tried.append(("enclosure", enc, None))
            # Strategy 1b: enclosure without query params (sometimes signed URLs break)
            if "?" in enc:
                tried.append(("enclosure_noquery", strip_query(enc), None))

        # Strategy 2: episode page (helps hosts that need extractor to find real audio)
        if page:
            tried.append(("page", page, page))  # referer = page

        # Strategy 3: notes page
        if notes and notes != page:
            tried.append(("notes", notes, notes))  # referer = notes

        success = False
        for label, url, referer in tried:
            cmd = build_cmd(dest, url, referer, args.fformat, args.rate_limit)
            try:
                subprocess.run(cmd, check=True)
                # confirm file present & non-empty
                if dest.exists() and dest.stat().st_size > 0:
                    oks.append({**r, "path": str(dest), "status": f"downloaded via {label}"})
                    success = True
                    break
            except subprocess.CalledProcessError as e:
                # Exponential-ish backoff
                time.sleep(1.5)
                continue

        if not success:
            fails.append({**r, "path": str(dest), "status": "failed_all_strategies"})
            hf = picked_host or "(unknown)"
            host_fail_counts[hf] = host_fail_counts.get(hf, 0) + 1

    # Write logs
    def write_log(path, rows):
        with open(path, "w", encoding="utf-8", newline="") as f:
            fields = list(rows[0].keys()) if rows else list(rows)
            # Stable fields if empty
            if not rows:
                fields = ["status"]
            w = csv.DictWriter(f, fieldnames=fields)
            w.writeheader()
            for row in rows:
                w.writerow(row)

    write_log(ok_log, oks)
    write_log(fail_log, fails)

    print(f"OK: {len(oks)}   FAIL: {len(fails)}")
    if host_fail_counts:
        print("Top failing hosts:")
        for h, c in sorted(host_fail_counts.items(), key=lambda kv: kv[1], reverse=True)[:20]:
            print(f"  {c:3d}  {h}")
    print(f"Logs: {ok_log}  {fail_log}")

if __name__ == "__main__":
    main()